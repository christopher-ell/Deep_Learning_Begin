{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For showing and formatting images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# For importing datasets into pytorch\n",
    "import torchvision.datasets as dataset\n",
    "\n",
    "# Used for dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# For pretrained resnet34 model\n",
    "import torchvision.models as models\n",
    "\n",
    "# For optimisation function\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# For turning data into tensors\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# For loss function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Tensor to wrap data in\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-grass  Common Chickweed  Loose Silky-bent   Shepherds Purse\r\n",
      "Charlock     Common wheat      Maize\t\t  Small-flowered Cranesbill\r\n",
      "Cleavers     Fat Hen\t       Scentless Mayweed  Sugar beet\r\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/cell/data/plant_seedlings/model/'\n",
    "!ls {PATH+\"train\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "sz = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image loaders\n",
    "## Dataset transforms puts the images in tensor form\n",
    "normalise = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_raw = dataset.ImageFolder(PATH+\"train\", transform=transforms.Compose([transforms.RandomResizedCrop(sz),\n",
    "                                                                            transforms.ToTensor(),\n",
    "                                                                           normalise]))\n",
    "train_loader = DataLoader(train_raw, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "valid_raw = dataset.ImageFolder(PATH+\"valid\", transform=transforms.Compose([transforms.CenterCrop(sz),\n",
    "                                                                            transforms.ToTensor(),\n",
    "                                                                           normalise]))\n",
    "valid_loader = DataLoader(valid_raw, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create resnet model\n",
    "resnet34=models.resnet34(pretrained=True)\n",
    "\n",
    "## Loss function and optimiser\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimiser = optim.Adam(resnet34.fc.parameters(), lr=0.001, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    #epoch=1\n",
    "    resnet34.train()\n",
    "    time_secs = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        start_time = time.time()\n",
    "        #print(batch_idx)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimiser.zero_grad()\n",
    "        output = resnet34(data)\n",
    "        loss=criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        time_secs += (time.time() - start_time)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\"Run time for 10 batches was: \", time_secs)\n",
    "            print('Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx*len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "            time_secs = 0\n",
    "            #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    resnet34.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        data, target = Variable(data, volatile = True), Variable(target)\n",
    "        output=resnet34(data)\n",
    "        test_loss += criterion(output, target).data[0]\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(valid_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(valid_loader.dataset),\n",
    "    100. * correct / len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time for 10 batches was:  7.7427427768707275\n",
      "Train epoch: 1 [0/3806 (0%)]\tLoss: 9.504869\n",
      "Run time for 10 batches was:  66.25943541526794\n",
      "Train epoch: 1 [160/3806 (4%)]\tLoss: 4.794926\n",
      "Run time for 10 batches was:  65.76920747756958\n",
      "Train epoch: 1 [320/3806 (8%)]\tLoss: 3.903837\n",
      "Run time for 10 batches was:  65.48485612869263\n",
      "Train epoch: 1 [480/3806 (13%)]\tLoss: 3.400758\n",
      "Run time for 10 batches was:  64.98099827766418\n",
      "Train epoch: 1 [640/3806 (17%)]\tLoss: 2.331260\n",
      "Run time for 10 batches was:  65.25183844566345\n",
      "Train epoch: 1 [800/3806 (21%)]\tLoss: 3.052902\n",
      "Run time for 10 batches was:  65.10970306396484\n",
      "Train epoch: 1 [960/3806 (25%)]\tLoss: 3.012307\n",
      "Run time for 10 batches was:  64.9295711517334\n",
      "Train epoch: 1 [1120/3806 (29%)]\tLoss: 2.803811\n",
      "Run time for 10 batches was:  65.06325435638428\n",
      "Train epoch: 1 [1280/3806 (34%)]\tLoss: 2.539026\n",
      "Run time for 10 batches was:  64.72999000549316\n",
      "Train epoch: 1 [1440/3806 (38%)]\tLoss: 2.780199\n",
      "Run time for 10 batches was:  65.13281917572021\n",
      "Train epoch: 1 [1600/3806 (42%)]\tLoss: 3.239116\n",
      "Run time for 10 batches was:  65.19238924980164\n",
      "Train epoch: 1 [1760/3806 (46%)]\tLoss: 2.774468\n",
      "Run time for 10 batches was:  65.51887321472168\n",
      "Train epoch: 1 [1920/3806 (50%)]\tLoss: 2.083964\n",
      "Run time for 10 batches was:  65.15035557746887\n",
      "Train epoch: 1 [2080/3806 (55%)]\tLoss: 2.482903\n",
      "Run time for 10 batches was:  65.2229688167572\n",
      "Train epoch: 1 [2240/3806 (59%)]\tLoss: 2.393405\n",
      "Run time for 10 batches was:  65.34444665908813\n",
      "Train epoch: 1 [2400/3806 (63%)]\tLoss: 2.042740\n",
      "Run time for 10 batches was:  65.31076502799988\n",
      "Train epoch: 1 [2560/3806 (67%)]\tLoss: 2.291155\n",
      "Run time for 10 batches was:  65.144784450531\n",
      "Train epoch: 1 [2720/3806 (71%)]\tLoss: 2.944923\n",
      "Run time for 10 batches was:  65.23147296905518\n",
      "Train epoch: 1 [2880/3806 (76%)]\tLoss: 1.547815\n",
      "Run time for 10 batches was:  65.19735479354858\n",
      "Train epoch: 1 [3040/3806 (80%)]\tLoss: 1.850880\n",
      "Run time for 10 batches was:  65.15305471420288\n",
      "Train epoch: 1 [3200/3806 (84%)]\tLoss: 2.290630\n",
      "Run time for 10 batches was:  65.31942081451416\n",
      "Train epoch: 1 [3360/3806 (88%)]\tLoss: 2.647099\n",
      "Run time for 10 batches was:  65.1439859867096\n",
      "Train epoch: 1 [3520/3806 (92%)]\tLoss: 1.983794\n",
      "Run time for 10 batches was:  65.10559725761414\n",
      "Train epoch: 1 [3680/3806 (97%)]\tLoss: 1.625284\n",
      "\n",
      "Test set: Average loss: 0.1420, Accuracy: 286/944 (30%)\n",
      "\n",
      "Run time for 10 batches was:  8.775299549102783\n",
      "Train epoch: 2 [0/3806 (0%)]\tLoss: 2.908413\n",
      "Run time for 10 batches was:  64.7167615890503\n",
      "Train epoch: 2 [160/3806 (4%)]\tLoss: 1.721650\n",
      "Run time for 10 batches was:  64.240234375\n",
      "Train epoch: 2 [320/3806 (8%)]\tLoss: 2.661526\n",
      "Run time for 10 batches was:  64.25817823410034\n",
      "Train epoch: 2 [480/3806 (13%)]\tLoss: 1.659295\n",
      "Run time for 10 batches was:  64.40736722946167\n",
      "Train epoch: 2 [640/3806 (17%)]\tLoss: 1.793904\n",
      "Run time for 10 batches was:  64.15085005760193\n",
      "Train epoch: 2 [800/3806 (21%)]\tLoss: 2.723224\n",
      "Run time for 10 batches was:  64.58527040481567\n",
      "Train epoch: 2 [960/3806 (25%)]\tLoss: 1.664659\n",
      "Run time for 10 batches was:  64.39248085021973\n",
      "Train epoch: 2 [1120/3806 (29%)]\tLoss: 1.285486\n",
      "Run time for 10 batches was:  64.21130084991455\n",
      "Train epoch: 2 [1280/3806 (34%)]\tLoss: 1.133133\n",
      "Run time for 10 batches was:  64.15682649612427\n",
      "Train epoch: 2 [1440/3806 (38%)]\tLoss: 1.746947\n",
      "Run time for 10 batches was:  64.30899333953857\n",
      "Train epoch: 2 [1600/3806 (42%)]\tLoss: 2.367414\n",
      "Run time for 10 batches was:  64.31110143661499\n",
      "Train epoch: 2 [1760/3806 (46%)]\tLoss: 2.050643\n",
      "Run time for 10 batches was:  64.17930126190186\n",
      "Train epoch: 2 [1920/3806 (50%)]\tLoss: 2.501825\n",
      "Run time for 10 batches was:  64.7381842136383\n",
      "Train epoch: 2 [2080/3806 (55%)]\tLoss: 1.600354\n",
      "Run time for 10 batches was:  65.1972234249115\n",
      "Train epoch: 2 [2240/3806 (59%)]\tLoss: 1.465097\n",
      "Run time for 10 batches was:  64.6867847442627\n",
      "Train epoch: 2 [2400/3806 (63%)]\tLoss: 1.858903\n",
      "Run time for 10 batches was:  65.00467348098755\n",
      "Train epoch: 2 [2560/3806 (67%)]\tLoss: 1.889080\n",
      "Run time for 10 batches was:  64.78906154632568\n",
      "Train epoch: 2 [2720/3806 (71%)]\tLoss: 1.662819\n",
      "Run time for 10 batches was:  64.80509042739868\n",
      "Train epoch: 2 [2880/3806 (76%)]\tLoss: 1.537745\n",
      "Run time for 10 batches was:  64.70541048049927\n",
      "Train epoch: 2 [3040/3806 (80%)]\tLoss: 0.927973\n",
      "Run time for 10 batches was:  64.58916401863098\n",
      "Train epoch: 2 [3200/3806 (84%)]\tLoss: 1.543815\n",
      "Run time for 10 batches was:  64.67041778564453\n",
      "Train epoch: 2 [3360/3806 (88%)]\tLoss: 1.794004\n",
      "Run time for 10 batches was:  64.7822015285492\n",
      "Train epoch: 2 [3520/3806 (92%)]\tLoss: 1.426121\n",
      "Run time for 10 batches was:  64.62479782104492\n",
      "Train epoch: 2 [3680/3806 (97%)]\tLoss: 1.447465\n",
      "\n",
      "Test set: Average loss: 0.1188, Accuracy: 349/944 (37%)\n",
      "\n",
      "Run time for 10 batches was:  8.820316791534424\n",
      "Train epoch: 3 [0/3806 (0%)]\tLoss: 1.443333\n",
      "Run time for 10 batches was:  65.18296027183533\n",
      "Train epoch: 3 [160/3806 (4%)]\tLoss: 1.427640\n",
      "Run time for 10 batches was:  64.76782941818237\n",
      "Train epoch: 3 [320/3806 (8%)]\tLoss: 1.578577\n",
      "Run time for 10 batches was:  64.9214916229248\n",
      "Train epoch: 3 [480/3806 (13%)]\tLoss: 1.763111\n",
      "Run time for 10 batches was:  65.20516562461853\n",
      "Train epoch: 3 [640/3806 (17%)]\tLoss: 1.290953\n",
      "Run time for 10 batches was:  64.62796878814697\n",
      "Train epoch: 3 [800/3806 (21%)]\tLoss: 1.034016\n",
      "Run time for 10 batches was:  64.65119791030884\n",
      "Train epoch: 3 [960/3806 (25%)]\tLoss: 1.231444\n",
      "Run time for 10 batches was:  64.95278143882751\n",
      "Train epoch: 3 [1120/3806 (29%)]\tLoss: 1.432326\n",
      "Run time for 10 batches was:  64.74897360801697\n",
      "Train epoch: 3 [1280/3806 (34%)]\tLoss: 1.467030\n",
      "Run time for 10 batches was:  64.80133533477783\n",
      "Train epoch: 3 [1440/3806 (38%)]\tLoss: 1.457930\n",
      "Run time for 10 batches was:  64.1527988910675\n",
      "Train epoch: 3 [1600/3806 (42%)]\tLoss: 1.328303\n",
      "Run time for 10 batches was:  62.193177461624146\n",
      "Train epoch: 3 [1760/3806 (46%)]\tLoss: 1.939077\n",
      "Run time for 10 batches was:  62.172731161117554\n",
      "Train epoch: 3 [1920/3806 (50%)]\tLoss: 1.309121\n",
      "Run time for 10 batches was:  62.014761447906494\n",
      "Train epoch: 3 [2080/3806 (55%)]\tLoss: 1.247027\n",
      "Run time for 10 batches was:  61.55985403060913\n",
      "Train epoch: 3 [2240/3806 (59%)]\tLoss: 1.703320\n",
      "Run time for 10 batches was:  61.30983257293701\n",
      "Train epoch: 3 [2400/3806 (63%)]\tLoss: 0.833393\n",
      "Run time for 10 batches was:  61.80925369262695\n",
      "Train epoch: 3 [2560/3806 (67%)]\tLoss: 1.584710\n",
      "Run time for 10 batches was:  62.63320064544678\n",
      "Train epoch: 3 [2720/3806 (71%)]\tLoss: 1.216819\n",
      "Run time for 10 batches was:  62.80350208282471\n",
      "Train epoch: 3 [2880/3806 (76%)]\tLoss: 1.394591\n",
      "Run time for 10 batches was:  62.953516244888306\n",
      "Train epoch: 3 [3040/3806 (80%)]\tLoss: 1.729054\n",
      "Run time for 10 batches was:  63.15757608413696\n",
      "Train epoch: 3 [3200/3806 (84%)]\tLoss: 1.182980\n",
      "Run time for 10 batches was:  63.357367753982544\n",
      "Train epoch: 3 [3360/3806 (88%)]\tLoss: 1.525140\n",
      "Run time for 10 batches was:  63.172938108444214\n",
      "Train epoch: 3 [3520/3806 (92%)]\tLoss: 1.804388\n",
      "Run time for 10 batches was:  62.93572402000427\n",
      "Train epoch: 3 [3680/3806 (97%)]\tLoss: 1.444497\n",
      "\n",
      "Test set: Average loss: 0.1046, Accuracy: 429/944 (45%)\n",
      "\n",
      "Run time for 10 batches was:  8.408449649810791\n",
      "Train epoch: 4 [0/3806 (0%)]\tLoss: 1.022823\n",
      "Run time for 10 batches was:  61.24379110336304\n",
      "Train epoch: 4 [160/3806 (4%)]\tLoss: 1.411261\n",
      "Run time for 10 batches was:  62.396018505096436\n",
      "Train epoch: 4 [320/3806 (8%)]\tLoss: 1.018312\n",
      "Run time for 10 batches was:  62.57188057899475\n",
      "Train epoch: 4 [480/3806 (13%)]\tLoss: 1.464237\n",
      "Run time for 10 batches was:  62.80959153175354\n",
      "Train epoch: 4 [640/3806 (17%)]\tLoss: 1.263135\n",
      "Run time for 10 batches was:  62.013248682022095\n",
      "Train epoch: 4 [800/3806 (21%)]\tLoss: 1.218367\n",
      "Run time for 10 batches was:  62.71510100364685\n",
      "Train epoch: 4 [960/3806 (25%)]\tLoss: 1.360833\n",
      "Run time for 10 batches was:  61.77858352661133\n",
      "Train epoch: 4 [1120/3806 (29%)]\tLoss: 1.558163\n",
      "Run time for 10 batches was:  61.872655630111694\n",
      "Train epoch: 4 [1280/3806 (34%)]\tLoss: 1.628415\n",
      "Run time for 10 batches was:  62.542436838150024\n",
      "Train epoch: 4 [1440/3806 (38%)]\tLoss: 1.222165\n",
      "Run time for 10 batches was:  62.886656045913696\n",
      "Train epoch: 4 [1600/3806 (42%)]\tLoss: 0.930472\n",
      "Run time for 10 batches was:  62.64767813682556\n",
      "Train epoch: 4 [1760/3806 (46%)]\tLoss: 1.866188\n",
      "Run time for 10 batches was:  62.552390813827515\n",
      "Train epoch: 4 [1920/3806 (50%)]\tLoss: 1.717728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time for 10 batches was:  63.041414976119995\n",
      "Train epoch: 4 [2080/3806 (55%)]\tLoss: 1.032371\n",
      "Run time for 10 batches was:  62.733288526535034\n",
      "Train epoch: 4 [2240/3806 (59%)]\tLoss: 1.704320\n",
      "Run time for 10 batches was:  62.28198742866516\n",
      "Train epoch: 4 [2400/3806 (63%)]\tLoss: 1.238079\n",
      "Run time for 10 batches was:  62.45811414718628\n",
      "Train epoch: 4 [2560/3806 (67%)]\tLoss: 1.115751\n",
      "Run time for 10 batches was:  61.95737075805664\n",
      "Train epoch: 4 [2720/3806 (71%)]\tLoss: 1.256768\n",
      "Run time for 10 batches was:  62.208385944366455\n",
      "Train epoch: 4 [2880/3806 (76%)]\tLoss: 1.208915\n",
      "Run time for 10 batches was:  61.88788318634033\n",
      "Train epoch: 4 [3040/3806 (80%)]\tLoss: 1.053379\n",
      "Run time for 10 batches was:  61.77302360534668\n",
      "Train epoch: 4 [3200/3806 (84%)]\tLoss: 1.110067\n",
      "Run time for 10 batches was:  62.416311264038086\n",
      "Train epoch: 4 [3360/3806 (88%)]\tLoss: 1.392629\n",
      "Run time for 10 batches was:  62.390942096710205\n",
      "Train epoch: 4 [3520/3806 (92%)]\tLoss: 1.059729\n",
      "Run time for 10 batches was:  62.1340537071228\n",
      "Train epoch: 4 [3680/3806 (97%)]\tLoss: 1.141433\n",
      "\n",
      "Test set: Average loss: 0.1102, Accuracy: 449/944 (48%)\n",
      "\n",
      "Run time for 10 batches was:  8.151244401931763\n",
      "Train epoch: 5 [0/3806 (0%)]\tLoss: 0.712157\n",
      "Run time for 10 batches was:  63.00780272483826\n",
      "Train epoch: 5 [160/3806 (4%)]\tLoss: 1.486533\n",
      "Run time for 10 batches was:  62.145835876464844\n",
      "Train epoch: 5 [320/3806 (8%)]\tLoss: 0.824431\n",
      "Run time for 10 batches was:  61.77436590194702\n",
      "Train epoch: 5 [480/3806 (13%)]\tLoss: 0.735899\n",
      "Run time for 10 batches was:  61.813085079193115\n",
      "Train epoch: 5 [640/3806 (17%)]\tLoss: 0.726054\n",
      "Run time for 10 batches was:  61.57111573219299\n",
      "Train epoch: 5 [800/3806 (21%)]\tLoss: 1.388108\n",
      "Run time for 10 batches was:  61.37032604217529\n",
      "Train epoch: 5 [960/3806 (25%)]\tLoss: 1.189470\n",
      "Run time for 10 batches was:  62.57654285430908\n",
      "Train epoch: 5 [1120/3806 (29%)]\tLoss: 1.084284\n",
      "Run time for 10 batches was:  62.856889486312866\n",
      "Train epoch: 5 [1280/3806 (34%)]\tLoss: 0.885563\n",
      "Run time for 10 batches was:  63.108787536621094\n",
      "Train epoch: 5 [1440/3806 (38%)]\tLoss: 1.040637\n",
      "Run time for 10 batches was:  62.86595058441162\n",
      "Train epoch: 5 [1600/3806 (42%)]\tLoss: 1.700431\n",
      "Run time for 10 batches was:  62.91177415847778\n",
      "Train epoch: 5 [1760/3806 (46%)]\tLoss: 1.024447\n",
      "Run time for 10 batches was:  62.94715476036072\n",
      "Train epoch: 5 [1920/3806 (50%)]\tLoss: 1.587169\n",
      "Run time for 10 batches was:  62.81943082809448\n",
      "Train epoch: 5 [2080/3806 (55%)]\tLoss: 1.104629\n",
      "Run time for 10 batches was:  62.97027277946472\n",
      "Train epoch: 5 [2240/3806 (59%)]\tLoss: 1.392826\n",
      "Run time for 10 batches was:  62.74474859237671\n",
      "Train epoch: 5 [2400/3806 (63%)]\tLoss: 1.009508\n",
      "Run time for 10 batches was:  62.717702865600586\n",
      "Train epoch: 5 [2560/3806 (67%)]\tLoss: 0.945929\n",
      "Run time for 10 batches was:  61.987972021102905\n",
      "Train epoch: 5 [2720/3806 (71%)]\tLoss: 1.533467\n",
      "Run time for 10 batches was:  61.54686188697815\n",
      "Train epoch: 5 [2880/3806 (76%)]\tLoss: 1.834650\n",
      "Run time for 10 batches was:  62.19899606704712\n",
      "Train epoch: 5 [3040/3806 (80%)]\tLoss: 1.024958\n",
      "Run time for 10 batches was:  62.97352051734924\n",
      "Train epoch: 5 [3200/3806 (84%)]\tLoss: 0.765911\n",
      "Run time for 10 batches was:  62.914384603500366\n",
      "Train epoch: 5 [3360/3806 (88%)]\tLoss: 0.711358\n",
      "Run time for 10 batches was:  62.938318729400635\n",
      "Train epoch: 5 [3520/3806 (92%)]\tLoss: 1.665559\n",
      "Run time for 10 batches was:  62.625168323516846\n",
      "Train epoch: 5 [3680/3806 (97%)]\tLoss: 1.558936\n",
      "\n",
      "Test set: Average loss: 0.1056, Accuracy: 465/944 (49%)\n",
      "\n",
      "Run time for 10 batches was:  8.677168607711792\n",
      "Train epoch: 6 [0/3806 (0%)]\tLoss: 1.161719\n",
      "Run time for 10 batches was:  63.48364067077637\n",
      "Train epoch: 6 [160/3806 (4%)]\tLoss: 0.898798\n",
      "Run time for 10 batches was:  62.89760375022888\n",
      "Train epoch: 6 [320/3806 (8%)]\tLoss: 1.166991\n",
      "Run time for 10 batches was:  63.11880326271057\n",
      "Train epoch: 6 [480/3806 (13%)]\tLoss: 1.372409\n",
      "Run time for 10 batches was:  62.64135766029358\n",
      "Train epoch: 6 [640/3806 (17%)]\tLoss: 0.796931\n",
      "Run time for 10 batches was:  61.46455526351929\n",
      "Train epoch: 6 [800/3806 (21%)]\tLoss: 0.924026\n",
      "Run time for 10 batches was:  62.528624057769775\n",
      "Train epoch: 6 [960/3806 (25%)]\tLoss: 0.812079\n",
      "Run time for 10 batches was:  62.945897340774536\n",
      "Train epoch: 6 [1120/3806 (29%)]\tLoss: 1.184369\n",
      "Run time for 10 batches was:  62.80055570602417\n",
      "Train epoch: 6 [1280/3806 (34%)]\tLoss: 1.539138\n",
      "Run time for 10 batches was:  62.820568799972534\n",
      "Train epoch: 6 [1440/3806 (38%)]\tLoss: 1.208930\n",
      "Run time for 10 batches was:  62.82763195037842\n",
      "Train epoch: 6 [1600/3806 (42%)]\tLoss: 1.464527\n",
      "Run time for 10 batches was:  62.73877549171448\n",
      "Train epoch: 6 [1760/3806 (46%)]\tLoss: 1.325877\n",
      "Run time for 10 batches was:  63.04968571662903\n",
      "Train epoch: 6 [1920/3806 (50%)]\tLoss: 1.406460\n",
      "Run time for 10 batches was:  62.76597261428833\n",
      "Train epoch: 6 [2080/3806 (55%)]\tLoss: 1.069736\n",
      "Run time for 10 batches was:  61.890724658966064\n",
      "Train epoch: 6 [2240/3806 (59%)]\tLoss: 1.351336\n",
      "Run time for 10 batches was:  63.04652190208435\n",
      "Train epoch: 6 [2400/3806 (63%)]\tLoss: 1.176773\n",
      "Run time for 10 batches was:  62.73497796058655\n",
      "Train epoch: 6 [2560/3806 (67%)]\tLoss: 0.855134\n",
      "Run time for 10 batches was:  62.51155424118042\n",
      "Train epoch: 6 [2720/3806 (71%)]\tLoss: 1.023032\n",
      "Run time for 10 batches was:  62.208932876586914\n",
      "Train epoch: 6 [2880/3806 (76%)]\tLoss: 0.969592\n",
      "Run time for 10 batches was:  62.262577533721924\n",
      "Train epoch: 6 [3040/3806 (80%)]\tLoss: 1.048153\n",
      "Run time for 10 batches was:  62.25296378135681\n",
      "Train epoch: 6 [3200/3806 (84%)]\tLoss: 1.330128\n",
      "Run time for 10 batches was:  62.3686306476593\n",
      "Train epoch: 6 [3360/3806 (88%)]\tLoss: 0.870970\n",
      "Run time for 10 batches was:  62.23292779922485\n",
      "Train epoch: 6 [3520/3806 (92%)]\tLoss: 0.730034\n",
      "Run time for 10 batches was:  62.11590123176575\n",
      "Train epoch: 6 [3680/3806 (97%)]\tLoss: 1.372644\n",
      "\n",
      "Test set: Average loss: 0.0977, Accuracy: 463/944 (49%)\n",
      "\n",
      "Run time for 10 batches was:  8.380413293838501\n",
      "Train epoch: 7 [0/3806 (0%)]\tLoss: 1.087438\n",
      "Run time for 10 batches was:  62.45591497421265\n",
      "Train epoch: 7 [160/3806 (4%)]\tLoss: 1.263443\n",
      "Run time for 10 batches was:  62.26990365982056\n",
      "Train epoch: 7 [320/3806 (8%)]\tLoss: 0.984592\n",
      "Run time for 10 batches was:  62.66162180900574\n",
      "Train epoch: 7 [480/3806 (13%)]\tLoss: 0.797443\n",
      "Run time for 10 batches was:  61.436556339263916\n",
      "Train epoch: 7 [640/3806 (17%)]\tLoss: 1.159118\n",
      "Run time for 10 batches was:  61.22390127182007\n",
      "Train epoch: 7 [800/3806 (21%)]\tLoss: 0.659159\n",
      "Run time for 10 batches was:  61.03265690803528\n",
      "Train epoch: 7 [960/3806 (25%)]\tLoss: 1.781722\n",
      "Run time for 10 batches was:  61.24646472930908\n",
      "Train epoch: 7 [1120/3806 (29%)]\tLoss: 0.652859\n",
      "Run time for 10 batches was:  61.0107421875\n",
      "Train epoch: 7 [1280/3806 (34%)]\tLoss: 1.759727\n",
      "Run time for 10 batches was:  61.07410264015198\n",
      "Train epoch: 7 [1440/3806 (38%)]\tLoss: 1.005755\n",
      "Run time for 10 batches was:  61.467612981796265\n",
      "Train epoch: 7 [1600/3806 (42%)]\tLoss: 1.586457\n",
      "Run time for 10 batches was:  61.01403331756592\n",
      "Train epoch: 7 [1760/3806 (46%)]\tLoss: 0.875061\n",
      "Run time for 10 batches was:  61.09197449684143\n",
      "Train epoch: 7 [1920/3806 (50%)]\tLoss: 0.826474\n",
      "Run time for 10 batches was:  61.10145902633667\n",
      "Train epoch: 7 [2080/3806 (55%)]\tLoss: 0.934280\n",
      "Run time for 10 batches was:  62.31471538543701\n",
      "Train epoch: 7 [2240/3806 (59%)]\tLoss: 1.092906\n",
      "Run time for 10 batches was:  62.575183153152466\n",
      "Train epoch: 7 [2400/3806 (63%)]\tLoss: 0.921934\n",
      "Run time for 10 batches was:  62.889126777648926\n",
      "Train epoch: 7 [2560/3806 (67%)]\tLoss: 0.888141\n",
      "Run time for 10 batches was:  62.68250775337219\n",
      "Train epoch: 7 [2720/3806 (71%)]\tLoss: 0.605955\n",
      "Run time for 10 batches was:  62.90426230430603\n",
      "Train epoch: 7 [2880/3806 (76%)]\tLoss: 1.199965\n",
      "Run time for 10 batches was:  62.73398208618164\n",
      "Train epoch: 7 [3040/3806 (80%)]\tLoss: 1.026196\n",
      "Run time for 10 batches was:  63.17657470703125\n",
      "Train epoch: 7 [3200/3806 (84%)]\tLoss: 0.843278\n",
      "Run time for 10 batches was:  62.769813537597656\n",
      "Train epoch: 7 [3360/3806 (88%)]\tLoss: 1.418148\n",
      "Run time for 10 batches was:  62.863847732543945\n",
      "Train epoch: 7 [3520/3806 (92%)]\tLoss: 0.576999\n",
      "Run time for 10 batches was:  62.97832679748535\n",
      "Train epoch: 7 [3680/3806 (97%)]\tLoss: 0.825060\n",
      "\n",
      "Test set: Average loss: 0.1046, Accuracy: 474/944 (50%)\n",
      "\n",
      "Run time for 10 batches was:  8.693426370620728\n",
      "Train epoch: 8 [0/3806 (0%)]\tLoss: 0.955399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time for 10 batches was:  63.123897314071655\n",
      "Train epoch: 8 [160/3806 (4%)]\tLoss: 1.135716\n",
      "Run time for 10 batches was:  63.100257396698\n",
      "Train epoch: 8 [320/3806 (8%)]\tLoss: 1.102621\n",
      "Run time for 10 batches was:  62.973812103271484\n",
      "Train epoch: 8 [480/3806 (13%)]\tLoss: 0.786348\n",
      "Run time for 10 batches was:  63.01951885223389\n",
      "Train epoch: 8 [640/3806 (17%)]\tLoss: 2.178388\n",
      "Run time for 10 batches was:  62.76961588859558\n",
      "Train epoch: 8 [800/3806 (21%)]\tLoss: 0.804844\n",
      "Run time for 10 batches was:  62.86982703208923\n",
      "Train epoch: 8 [960/3806 (25%)]\tLoss: 1.095928\n",
      "Run time for 10 batches was:  62.62620949745178\n",
      "Train epoch: 8 [1120/3806 (29%)]\tLoss: 0.873884\n",
      "Run time for 10 batches was:  62.786614418029785\n",
      "Train epoch: 8 [1280/3806 (34%)]\tLoss: 1.027603\n",
      "Run time for 10 batches was:  62.75418972969055\n",
      "Train epoch: 8 [1440/3806 (38%)]\tLoss: 1.337286\n",
      "Run time for 10 batches was:  63.024214029312134\n",
      "Train epoch: 8 [1600/3806 (42%)]\tLoss: 0.874333\n",
      "Run time for 10 batches was:  62.81673240661621\n",
      "Train epoch: 8 [1760/3806 (46%)]\tLoss: 1.244121\n",
      "Run time for 10 batches was:  62.79929184913635\n",
      "Train epoch: 8 [1920/3806 (50%)]\tLoss: 2.231579\n",
      "Run time for 10 batches was:  62.98816227912903\n",
      "Train epoch: 8 [2080/3806 (55%)]\tLoss: 1.638712\n",
      "Run time for 10 batches was:  62.897167444229126\n",
      "Train epoch: 8 [2240/3806 (59%)]\tLoss: 0.870399\n",
      "Run time for 10 batches was:  62.93545961380005\n",
      "Train epoch: 8 [2400/3806 (63%)]\tLoss: 0.587524\n",
      "Run time for 10 batches was:  62.776084661483765\n",
      "Train epoch: 8 [2560/3806 (67%)]\tLoss: 1.415486\n",
      "Run time for 10 batches was:  62.94812893867493\n",
      "Train epoch: 8 [2720/3806 (71%)]\tLoss: 1.392270\n",
      "Run time for 10 batches was:  62.87740516662598\n",
      "Train epoch: 8 [2880/3806 (76%)]\tLoss: 0.816444\n",
      "Run time for 10 batches was:  62.92909240722656\n",
      "Train epoch: 8 [3040/3806 (80%)]\tLoss: 1.154102\n",
      "Run time for 10 batches was:  62.73447275161743\n",
      "Train epoch: 8 [3200/3806 (84%)]\tLoss: 1.552774\n",
      "Run time for 10 batches was:  62.93601679801941\n",
      "Train epoch: 8 [3360/3806 (88%)]\tLoss: 1.902196\n",
      "Run time for 10 batches was:  62.62532997131348\n",
      "Train epoch: 8 [3520/3806 (92%)]\tLoss: 1.105476\n",
      "Run time for 10 batches was:  62.53464198112488\n",
      "Train epoch: 8 [3680/3806 (97%)]\tLoss: 1.204444\n",
      "\n",
      "Test set: Average loss: 0.0932, Accuracy: 487/944 (52%)\n",
      "\n",
      "Run time for 10 batches was:  8.503117084503174\n",
      "Train epoch: 9 [0/3806 (0%)]\tLoss: 0.886029\n",
      "Run time for 10 batches was:  63.57010555267334\n",
      "Train epoch: 9 [160/3806 (4%)]\tLoss: 1.238798\n",
      "Run time for 10 batches was:  62.96647119522095\n",
      "Train epoch: 9 [320/3806 (8%)]\tLoss: 0.887665\n",
      "Run time for 10 batches was:  62.564531564712524\n",
      "Train epoch: 9 [480/3806 (13%)]\tLoss: 1.353581\n",
      "Run time for 10 batches was:  62.51317095756531\n",
      "Train epoch: 9 [640/3806 (17%)]\tLoss: 1.626372\n",
      "Run time for 10 batches was:  62.572617530822754\n",
      "Train epoch: 9 [800/3806 (21%)]\tLoss: 1.051474\n",
      "Run time for 10 batches was:  62.505775690078735\n",
      "Train epoch: 9 [960/3806 (25%)]\tLoss: 0.786962\n",
      "Run time for 10 batches was:  62.77999305725098\n",
      "Train epoch: 9 [1120/3806 (29%)]\tLoss: 1.125866\n",
      "Run time for 10 batches was:  62.446351528167725\n",
      "Train epoch: 9 [1280/3806 (34%)]\tLoss: 0.773471\n",
      "Run time for 10 batches was:  62.54678010940552\n",
      "Train epoch: 9 [1440/3806 (38%)]\tLoss: 0.920973\n",
      "Run time for 10 batches was:  62.93903470039368\n",
      "Train epoch: 9 [1600/3806 (42%)]\tLoss: 1.157837\n",
      "Run time for 10 batches was:  62.81593203544617\n",
      "Train epoch: 9 [1760/3806 (46%)]\tLoss: 1.460882\n",
      "Run time for 10 batches was:  63.07703709602356\n",
      "Train epoch: 9 [1920/3806 (50%)]\tLoss: 1.200364\n",
      "Run time for 10 batches was:  62.86112999916077\n",
      "Train epoch: 9 [2080/3806 (55%)]\tLoss: 0.532358\n",
      "Run time for 10 batches was:  62.77011299133301\n",
      "Train epoch: 9 [2240/3806 (59%)]\tLoss: 0.951254\n",
      "Run time for 10 batches was:  62.69955801963806\n",
      "Train epoch: 9 [2400/3806 (63%)]\tLoss: 1.414414\n",
      "Run time for 10 batches was:  63.05493998527527\n",
      "Train epoch: 9 [2560/3806 (67%)]\tLoss: 1.120383\n",
      "Run time for 10 batches was:  63.0652174949646\n",
      "Train epoch: 9 [2720/3806 (71%)]\tLoss: 0.950894\n",
      "Run time for 10 batches was:  63.10040783882141\n",
      "Train epoch: 9 [2880/3806 (76%)]\tLoss: 0.943691\n",
      "Run time for 10 batches was:  62.77872943878174\n",
      "Train epoch: 9 [3040/3806 (80%)]\tLoss: 1.627166\n",
      "Run time for 10 batches was:  61.887932538986206\n",
      "Train epoch: 9 [3200/3806 (84%)]\tLoss: 0.919533\n",
      "Run time for 10 batches was:  62.68618178367615\n",
      "Train epoch: 9 [3360/3806 (88%)]\tLoss: 1.046286\n",
      "Run time for 10 batches was:  62.83126902580261\n",
      "Train epoch: 9 [3520/3806 (92%)]\tLoss: 1.643715\n",
      "Run time for 10 batches was:  62.758830547332764\n",
      "Train epoch: 9 [3680/3806 (97%)]\tLoss: 0.882295\n",
      "\n",
      "Test set: Average loss: 0.1085, Accuracy: 448/944 (47%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Loop through epochs training data and then testing it\n",
    "for epoch in range(1,10):\n",
    "    train(epoch)\n",
    "    validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
