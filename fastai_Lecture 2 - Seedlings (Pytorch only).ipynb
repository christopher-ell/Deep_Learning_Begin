{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For showing and formatting images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# For importing datasets into pytorch\n",
    "import torchvision.datasets as dataset\n",
    "\n",
    "# Used for dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# For pretrained resnet34 model\n",
    "import torchvision.models as models\n",
    "\n",
    "# For optimisation function\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# For turning data into tensors\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# For loss function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Tensor to wrap data in\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-grass  Common Chickweed  Loose Silky-bent   Shepherds Purse\r\n",
      "Charlock     Common wheat      Maize\t\t  Small-flowered Cranesbill\r\n",
      "Cleavers     Fat Hen\t       Scentless Mayweed  Sugar beet\r\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/cell/data/plant_seedlings/model/'\n",
    "!ls {PATH+\"train\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "sz = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image loaders\n",
    "## Dataset transforms puts the images in tensor form\n",
    "normalise = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_raw = dataset.ImageFolder(PATH+\"train\", transform=transforms.Compose([transforms.RandomResizedCrop(sz),\n",
    "                                                                            transforms.RandomHorizontalFlip(),\n",
    "                                                                            transforms.ToTensor(),\n",
    "                                                                           normalise]))\n",
    "train_loader = DataLoader(train_raw, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "valid_raw = dataset.ImageFolder(PATH+\"valid\", transform=transforms.Compose([transforms.CenterCrop(sz),\n",
    "                                                                            transforms.ToTensor(),\n",
    "                                                                           normalise]))\n",
    "valid_loader = DataLoader(valid_raw, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "## Create resnet model\n",
    "resnet34=models.resnet34(pretrained=True)\n",
    "\n",
    "num_ftrs = resnet34.fc.in_features\n",
    "\n",
    "## Freeze all but the last layers\n",
    "for param in resnet34.parameters():\n",
    "    ## Each tensor has the flag requires_grad, setting it to false allows freezes\n",
    "    ## the parmaeter associated with it\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "## Create new modules that will become final layer\n",
    "num_ftrs = resnet34.fc.in_features\n",
    "print(num_ftrs)\n",
    "## Give final layers a linear transform with twelve outputs one for each category\n",
    "resnet34.fc = nn.Linear(num_ftrs, 12)\n",
    "\n",
    "## Create new model and tell it whether the computer has a GPU or not\n",
    "\n",
    "## Loss function and optimiser\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimiser = optim.Adam(resnet34.fc.parameters(), lr=0.001, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    #epoch=1\n",
    "    resnet34.train()\n",
    "    time_secs = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        start_time = time.time()\n",
    "        #print(batch_idx)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimiser.zero_grad()\n",
    "        output = resnet34(data)\n",
    "        #print(\"Output: \", output)\n",
    "        #print(\"Target: \", target)\n",
    "        loss=criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        time_secs += (time.time() - start_time)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\"Run time for 10 batches was: \", time_secs)\n",
    "            print('Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx*len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "            time_secs = 0\n",
    "            #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    resnet34.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        data, target = Variable(data, volatile = True), Variable(target)\n",
    "        output=resnet34(data)\n",
    "        test_loss += criterion(output, target).data[0]\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(valid_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(valid_loader.dataset),\n",
    "    100. * correct / len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.5781  0.2121  0.1887  0.1256  0.1281 -0.4158  0.2003  0.5057 -0.3397 -0.8250\n",
      "-0.4615  0.7388  0.4439  0.5166  0.3363 -0.2362 -0.1420  0.0351 -0.5715 -1.3180\n",
      "-1.1999 -0.5109  1.2589  0.3908  0.2174 -0.2964  0.2744 -0.3217  0.2991 -0.7562\n",
      "-0.2953  0.3476  0.4944  0.0418  0.5776  0.0504  0.5304 -0.1825  0.1079 -0.3640\n",
      "-0.4578  0.9297  0.2212  0.4896  1.1289 -0.5055 -0.1432  0.7535  0.0053 -0.2456\n",
      "-0.0545 -0.0128 -0.2323  0.5592  0.4527 -0.4668  0.3685  0.5290 -0.1497 -0.7779\n",
      "-0.4005  0.6472  0.5912  0.1947 -0.1378 -0.4433 -0.0601  0.4183 -0.1995 -0.5660\n",
      "-0.4064  0.1907  0.4220  0.1865  0.2150  0.5875  0.1740  0.1138 -0.0774 -0.1449\n",
      "-0.5153  0.1477  0.2279  0.6471 -0.2252  0.1533  0.2594 -0.1888 -0.5515 -0.9588\n",
      "-0.7457  0.5043  0.4228 -0.0536  0.5350  0.2258  0.7039  0.4885  0.4011 -0.6735\n",
      " 0.1123 -0.1620  0.3412  0.8027  0.4842  0.6364 -0.1176  0.0033 -0.8034 -0.1077\n",
      "-0.3091  0.2033  0.4059  0.5919  0.2267 -0.4789  0.3526 -0.1479  0.1699 -1.0891\n",
      " 0.7509  1.0287 -0.2378 -0.0829  0.3217 -0.7881  1.1697  1.0943 -0.8335 -0.6532\n",
      "-0.1022 -0.0241 -0.3871  1.0267  0.2407 -0.2304 -0.2515  0.4183  0.2346 -0.0522\n",
      "-1.0802  0.5636 -0.3311  1.3782  0.8912 -0.5711 -0.1382  0.4211 -0.4439  0.4031\n",
      "-0.1094 -0.6817  0.2369  0.0996  0.4997 -0.2229  0.2694  0.1645 -0.6497 -0.5458\n",
      "\n",
      "Columns 10 to 11 \n",
      " 1.2668  0.0801\n",
      " 0.8920 -0.3148\n",
      " 1.0278  0.2485\n",
      " 0.2415 -0.4545\n",
      " 0.1494 -0.5102\n",
      " 0.7610 -0.3314\n",
      " 1.0664 -0.4540\n",
      " 1.2717 -1.2535\n",
      " 0.1874  0.3688\n",
      " 0.9303  0.4352\n",
      " 0.8594  0.1998\n",
      " 0.0402 -0.2212\n",
      "-0.3528 -0.4687\n",
      " 1.1659 -0.4034\n",
      " 0.9561 -0.4153\n",
      " 0.2381 -0.6804\n",
      "[torch.FloatTensor of size 16x12]\n",
      "\n",
      "Target:  Variable containing:\n",
      " 11\n",
      "  7\n",
      " 10\n",
      "  7\n",
      "  2\n",
      "  6\n",
      "  7\n",
      "  9\n",
      "  9\n",
      " 11\n",
      "  7\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  6\n",
      " 12\n",
      "[torch.LongTensor of size 16]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THNN/generic/ClassNLLCriterion.c:87",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f0124059db5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Loop through epochs training data and then testing it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-646119080d3d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 679\u001b[0;31m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \"\"\"\n\u001b[0;32m-> 1161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THNN/generic/ClassNLLCriterion.c:87"
     ]
    }
   ],
   "source": [
    "## Loop through epochs training data and then testing it\n",
    "for epoch in range(1,10):\n",
    "    train(epoch)\n",
    "    validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
