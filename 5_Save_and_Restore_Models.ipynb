{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5 Save and Restore Models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christopher-ell/Deep_Learning_Begin/blob/master/5_Save_and_Restore_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zJWg1Wa0ubYg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Source: https://www.tensorflow.org/tutorials/keras/save_and_restore_models"
      ]
    },
    {
      "metadata": {
        "id": "9Q3xpz597Sfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "Generally training basic models, saving and then loading them in different ways:\n",
        "\n",
        "1. Download MNIST dataset from keras datasets splitting into relevant sections\n",
        "2. Create the new model architure in a function so that it can be called anytime you want a new model\n",
        "3. Create and train new model creating a callback function that tells the model to save the model weights at each epoch during training\n",
        "4. Create new model, load trained weights from above model and evaluate accuracy\n",
        "5. Create and train new model creating a callback function that tells the model to save the weights at each checkpoint (5 epochs), using period.\n",
        "6. Create new model and load latest trained weights, evaluate this model before and after loading weights\n",
        "7. Manually save weights of model already created rather than during training. Then create new model and evaluate before and after loading above trained weights.\n",
        "8. Create and train new model. Save it as a HDF5 which means you can not only save weights but optimisation and model configuration.\n",
        "9. Create new model loading above model at the same time and evaluate to ensure it gets the same accuracy as the loaded model."
      ]
    },
    {
      "metadata": {
        "id": "esVfh8-RuCep",
        "colab_type": "code",
        "outputId": "dfd90d72-9446-49ac-dbf6-f9576ad803a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "lSPmsCwBudyd",
        "colab_type": "code",
        "outputId": "dca39214-7f6b-4d79-80d3-5c074430ec51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "## Download data from the standard keras datasets dividing it into training and \n",
        "## testing data and data and labels\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "## Remove the first 10,000 labels\n",
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "## Remove the first 10,000 images, reshape the matrix of images into a \n",
        "## vector and then divide by 255 so all cells are between 0 and 1\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_M6_mS3Mv6xy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define Model**"
      ]
    },
    {
      "metadata": {
        "id": "N0gn6MiCv1N1",
        "colab_type": "code",
        "outputId": "83a97d47-ac16-4c39-cec1-6109713c1b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "# Returns a short sequential model\n",
        "## Structure of model to be used\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      ## STack a layer with 512 nodes and a relu activation function.\n",
        "      ## The number of parameters is equal to inputs (784) x nodes (512) + nodes (512)\n",
        "      ## input_shape is input data shape\n",
        "      keras.layers.Dense(512, activation = tf.nn.relu, input_shape = (784, )),\n",
        "      ## Apply dropout as a form of regularisation to the cells of the activation \n",
        "      ## layer\n",
        "      ## Drop out will randomly select 20% of the cells and make their value 0\n",
        "      keras.layers.Dropout(0.2),\n",
        "      ## The final layer will have 10 nodes and softmax activation function\n",
        "      ## The number of parameters is equal to inputs (512) x \n",
        "      keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "  ])\n",
        "  \n",
        "  ## How the gradient descent algorithm will optimize the parameters\n",
        "                ## Will use adam gradient descent algorithm\n",
        "  model.compile(optimizer = 'adam',\n",
        "                ## Will use sparse_categorical_crossentropy loss function\n",
        "                loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                ## Will track accuracy metric history each epoch of training\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create a basic model instance\n",
        "## Create instance of model\n",
        "model = create_model()\n",
        "## Create summary of model instance\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gk8PTZXfxxjb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Saving Checkpoints During Training**\n",
        "\n",
        "Checkpoint callback usage"
      ]
    },
    {
      "metadata": {
        "id": "OXENaKKLxSNu",
        "colab_type": "code",
        "outputId": "c40e2fe6-5569-4f83-c994-f2f4a4ec230a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1316
        }
      },
      "cell_type": "code",
      "source": [
        "## Path that the model backups will be saved in\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "## Convert path string into directory\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create checkpoint callback\n",
        "## Callback that save the model weights to the specified path\n",
        "## Function saves to model at checkpoint\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "                                                save_weights_only = True,\n",
        "                                                verbose = 1)\n",
        "\n",
        "## Create instance of the model\n",
        "model = create_model()\n",
        "\n",
        "## Fit the model by loading training data, running it for 10 epochs, \n",
        "## specifying the validation data and telling the model to save using the checkpoint callback\n",
        "model.fit(train_images, train_labels, epochs = 10,\n",
        "         validation_data = (test_images, test_labels),\n",
        "         callbacks = [cp_callback]) # pass callback to training"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 1.2132 - acc: 0.6507\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 1.1636 - acc: 0.6670 - val_loss: 0.7159 - val_acc: 0.7790\n",
            "Epoch 2/10\n",
            " 864/1000 [========================>.....] - ETA: 0s - loss: 0.4207 - acc: 0.8889\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 329us/step - loss: 0.4201 - acc: 0.8850 - val_loss: 0.5294 - val_acc: 0.8190\n",
            "Epoch 3/10\n",
            " 832/1000 [=======================>......] - ETA: 0s - loss: 0.3053 - acc: 0.9075\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 343us/step - loss: 0.3132 - acc: 0.9070 - val_loss: 0.4812 - val_acc: 0.8580\n",
            "Epoch 4/10\n",
            " 832/1000 [=======================>......] - ETA: 0s - loss: 0.2136 - acc: 0.9507\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 351us/step - loss: 0.2102 - acc: 0.9540 - val_loss: 0.4258 - val_acc: 0.8740\n",
            "Epoch 5/10\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.1563 - acc: 0.9667\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 350us/step - loss: 0.1571 - acc: 0.9660 - val_loss: 0.4198 - val_acc: 0.8650\n",
            "Epoch 6/10\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9788\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 349us/step - loss: 0.1102 - acc: 0.9790 - val_loss: 0.4167 - val_acc: 0.8600\n",
            "Epoch 7/10\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9859\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 352us/step - loss: 0.0971 - acc: 0.9860 - val_loss: 0.4013 - val_acc: 0.8640\n",
            "Epoch 8/10\n",
            " 832/1000 [=======================>......] - ETA: 0s - loss: 0.0617 - acc: 0.9928\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 333us/step - loss: 0.0633 - acc: 0.9910 - val_loss: 0.4156 - val_acc: 0.8690\n",
            "Epoch 9/10\n",
            " 864/1000 [========================>.....] - ETA: 0s - loss: 0.0471 - acc: 0.9988\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 338us/step - loss: 0.0495 - acc: 0.9980 - val_loss: 0.4019 - val_acc: 0.8690\n",
            "Epoch 10/10\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9970\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3273e7d748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 363us/step - loss: 0.0419 - acc: 0.9970 - val_loss: 0.4082 - val_acc: 0.8630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3273df0cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "xNS1qpDmzLvQ",
        "colab_type": "code",
        "outputId": "6694e78a-19b1-4b20-a835-59e7ee6f2848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "## Creates a single collection of Tensorflow checkpoint files\n",
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  cp.ckpt.data-00000-of-00001  cp.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xwE2y-qN0vIN",
        "colab_type": "code",
        "outputId": "63f655d2-4e1c-476b-abcf-0d2b3d78fd63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "## Create new instance of the model\n",
        "model = create_model()\n",
        "\n",
        "## Evaluate the accuracy of the newly created untrained model on \n",
        "## the validation data\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "## Print untrained models accuracy\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 167us/step\n",
            "Untrained model, accuracy:  6.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YPbSE73v1V-1",
        "colab_type": "code",
        "outputId": "5dab415f-e146-46fe-db51-3ebfc671a67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "## Load the previously saved weights into the above created model\n",
        "model.load_weights(checkpoint_path)\n",
        "## Evaluate the accuracy again of the newly created model with the \n",
        "## loaded weights\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "## Print the accuracy of the newly created model with the loaded weights\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 56us/step\n",
            "Restored model, accuracy: 86.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6VyhJ7H_17ta",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checkpoint callback Options"
      ]
    },
    {
      "metadata": {
        "id": "LS-60Ai-14EQ",
        "colab_type": "code",
        "outputId": "035b8696-d740-472a-c90f-7ed3fa715095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        }
      },
      "cell_type": "code",
      "source": [
        "# Include the epoch in the file name. (uses 'str.format')\n",
        "## Create a new directory to save another model\n",
        "checkpoint_path = 'training_2/cp-{epoch:04d}.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "## Create checkpoint that saves the weights of the model to the specified\n",
        "## directory every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "  checkpoint_path, verbose = 1, save_weights_only = True,\n",
        "  # Save weights, every 5-epochs.\n",
        "    period = 5)\n",
        "\n",
        "## Create new model instance\n",
        "model = create_model()\n",
        "## Train the parameters of the new model instance on the training data, \n",
        "## with 50 epcohs, test data as validation and using the callback to save \n",
        "## the model every 50 epochs\n",
        "model.fit(train_images, train_labels,\n",
        "         epochs = 50, callbacks = [cp_callback],\n",
        "         validation_data = (test_images, test_labels),\n",
        "         verbose = 0)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "\n",
            "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "\n",
            "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "\n",
            "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "\n",
            "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "\n",
            "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "\n",
            "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "\n",
            "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "\n",
            "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "\n",
            "Epoch 00050: saving model to training_2/cp-0050.ckpt\n",
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e913cf8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f32835c86d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "KddPq4zs3Kjw",
        "colab_type": "code",
        "outputId": "65c5d154-b98b-4d38-cf1b-139753f4d05a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "cell_type": "code",
      "source": [
        "## List all versions of the model saved at each checkpoint (5 epochs)\n",
        "! ls {checkpoint_dir}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t  cp-0030.ckpt.data-00000-of-00001\n",
            "cp-0005.ckpt.data-00000-of-00001  cp-0030.ckpt.index\n",
            "cp-0005.ckpt.index\t\t  cp-0035.ckpt.data-00000-of-00001\n",
            "cp-0010.ckpt.data-00000-of-00001  cp-0035.ckpt.index\n",
            "cp-0010.ckpt.index\t\t  cp-0040.ckpt.data-00000-of-00001\n",
            "cp-0015.ckpt.data-00000-of-00001  cp-0040.ckpt.index\n",
            "cp-0015.ckpt.index\t\t  cp-0045.ckpt.data-00000-of-00001\n",
            "cp-0020.ckpt.data-00000-of-00001  cp-0045.ckpt.index\n",
            "cp-0020.ckpt.index\t\t  cp-0050.ckpt.data-00000-of-00001\n",
            "cp-0025.ckpt.data-00000-of-00001  cp-0050.ckpt.index\n",
            "cp-0025.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sx4Z8P5yBgk_",
        "colab_type": "code",
        "outputId": "e4e61a0f-9dba-4fee-bac3-8cc7271ba060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "## FUnction finds the name of the latest checkpoint saved\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "## Output the name of the latest checkpoint\n",
        "latest"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training_2/cp-0050.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "u3Caa6a4BpHt",
        "colab_type": "code",
        "outputId": "caa14887-7094-4eea-cfd9-bb0bee57cd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "## Create new instance of the model\n",
        "model = create_model()\n",
        "## Load the latest version of the models weights\n",
        "model.load_weights(latest)\n",
        "## Evaluate the newly created model with the latest weights\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "## Print accuracy of the newly loaded model with latest weights\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 150us/step\n",
            "Restored model, accuracy: 87.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x7NoLzKFCYOK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Manually Save Weights**"
      ]
    },
    {
      "metadata": {
        "id": "ky5yO3P6CFGM",
        "colab_type": "code",
        "outputId": "60db380c-a51d-44e6-fe4b-9847c441f2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the Weights\n",
        "## Manually save weights of model already created rather than saving\n",
        "## the weights during the training process\n",
        "model.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Restore the Weights\n",
        "## Create a new model with untrained weights\n",
        "model = create_model()\n",
        "## Load the trained weights into the newly created model\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "## Evaluate the newly created model with loaded weights using the test data\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "## Output the accuracy of the model\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f326e4b85f8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "1000/1000 [==============================] - 0s 161us/step\n",
            "Restored model, accuracy: 87.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jQ4IveH-DtRE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Save the Entire Model**"
      ]
    },
    {
      "metadata": {
        "id": "I4AjrfCcDz-C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As a HDF5 File"
      ]
    },
    {
      "metadata": {
        "id": "5w97fZv_DDyH",
        "colab_type": "code",
        "outputId": "dd3cd1a1-2d2c-481d-a74f-9c2284ca0b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "cell_type": "code",
      "source": [
        "## Saving the model as a HDF5 not only saves he model weights but also model and\n",
        "## optimizer configuration\n",
        "\n",
        "## Create a new instance of the model\n",
        "model = create_model()\n",
        "\n",
        "# You need to use a keras optimizer to restore the optimizer state from a HDF5 file.\n",
        "## Train the newly created models untrained parameters using adam gradient descent\n",
        "## algorithm, a sparse categorical crossentropy loss function and track accuracy \n",
        "## metrics per epoch\n",
        "model.compile(optimizer = 'adam',\n",
        "             loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
        "             metrics = ['accuracy'])\n",
        "\n",
        "## Fit the model over 5 epochs with the training data\n",
        "model.fit(train_images, train_labels, epochs = 5)\n",
        "\n",
        "# Save entire model to HDF5 file\n",
        "## Save the entire model as a HDF5. \n",
        "## This not only save weights but the model (architecture) and poptimiser \n",
        "## configurations SO we can start training a model from where its training \n",
        "## left off\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 1s 669us/step - loss: 1.1504 - acc: 0.6810\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 254us/step - loss: 0.4193 - acc: 0.8860\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 256us/step - loss: 0.2833 - acc: 0.9230\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 267us/step - loss: 0.2008 - acc: 0.9590\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 258us/step - loss: 0.1510 - acc: 0.9710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m8hCPhkxEkMu",
        "colab_type": "code",
        "outputId": "b4755b94-11a3-4647-d0f1-b96583ef373f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "## Create a new instance of the model loading the previously HDF5 saved model\n",
        "new_model = keras.models.load_model('my_model.h5')\n",
        "## Print a summary of the newly created model with the previous parameters\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4jaWMEo3E1lN",
        "colab_type": "code",
        "outputId": "64ba0604-c8cd-48ca-8b80-844ddfa2af9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "## Evaluate the previously loaded model using training data\n",
        "loss, acc = new_model.evaluate(test_images, test_labels)\n",
        "## Print the accuracy of the model\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 211us/step\n",
            "Restored model, accuracy: 85.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TwrtA9yBFW5o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As Saved Model"
      ]
    },
    {
      "metadata": {
        "id": "cnp1YbSbFL0c",
        "colab_type": "code",
        "outputId": "bf198536-fc28-4f2b-a07e-57fc8af5e82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "cell_type": "code",
      "source": [
        "## Create new instance of the model\n",
        "model = create_model()\n",
        "\n",
        "## FIt the new model with training data in 5 epochs\n",
        "model.fit(train_images, train_labels, epochs = 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 1s 776us/step - loss: 1.1926 - acc: 0.6350\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 275us/step - loss: 0.4168 - acc: 0.8910\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 257us/step - loss: 0.2824 - acc: 0.9230\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 255us/step - loss: 0.2079 - acc: 0.9540\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 260us/step - loss: 0.1654 - acc: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3274c41a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "aJ76VpqdFgl6",
        "colab_type": "code",
        "outputId": "86ff7c5f-14f2-4cc9-dfe4-fa72127e210c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "cell_type": "code",
      "source": [
        "## Save the whole model manually to the specified path\n",
        "saved_model_path = tf.contrib.saved_model.save_keras_model(model, \"./saved_models\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f3270154f60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "WARNING:tensorflow:Model was compiled with an optimizer, but the optimizer is not from `tf.train` (e.g. `tf.train.AdagradOptimizer`). Only the serving graph was exported. The train and evaluate graphs were not added to the SavedModel.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./saved_models/temp-b'1545186574'/saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uCTj_cqUFwo4",
        "colab_type": "code",
        "outputId": "5efd1a7c-a49f-4aff-be06-01e3ceb62e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "## list of directories in the saved_models folder\n",
        "! ls saved_models/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1545186574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R4Y_7PeoF1AZ",
        "colab_type": "code",
        "outputId": "194d1620-77e9-4ea0-cf8a-550c04a8a97b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "## Load the above saved model into a new model\n",
        "new_model = tf.contrib.saved_model.load_keras_model(saved_model_path)\n",
        "## Output the new model\n",
        "new_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f3267891ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "s3pRIGX5GBCH",
        "colab_type": "code",
        "outputId": "7f55905b-a318-4957-bef2-d09869722e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# The optimizer was not restored\n",
        "## Specify how a model will optimize its weights using adam gradient descent\n",
        "## the sparse categorical crossentropy loss function and tracking accuracy metrics \n",
        "## each epoch\n",
        "new_model.compile(optimizer = 'adam',\n",
        "                 loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                 metrics = [\"accuracy\"])\n",
        "\n",
        "## Evaluate the new model using test data\n",
        "loss, acc = new_model.evaluate(test_images, test_labels)\n",
        "## Output the accuracy of the new model\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 471us/step\n",
            "Restored model, accuracy: 85.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aBJCIB0VGkJW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}