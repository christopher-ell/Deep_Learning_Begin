{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9. Custom Layers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christopher-ell/Deep_Learning_Begin/blob/master/9_Custom_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "iQRhOUPmsT1-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Soucre: https://www.tensorflow.org/tutorials/eager/custom_layers"
      ]
    },
    {
      "metadata": {
        "id": "XDe8TwWosSJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1p9X9FdssjzL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Layers: Common Sets of Useful Operations**"
      ]
    },
    {
      "metadata": {
        "id": "E76OTpFKsi_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In the tf.keras.layers package, layers are objects. To construct a layer,\n",
        "# simply construct the object. Most layers take as a first argument the number\n",
        "# of outputs dimensions / channels\n",
        "## Create layer with 100 nodes so it has 100 outputs and however many inputs as\n",
        "## required, since this is unspecified.\n",
        "layer = tf.keras.layers.Dense(100)\n",
        "# The number of input dimensions is often unnecessary, as it can be inferred\n",
        "# the first time the layer is used, but it can be provided if you want to \n",
        "# specify it manually, which is useful in some complex models.\n",
        "## Create a layer with 10 nodes and so 10 outputs. The inputs are specified \n",
        "## with however many rows and 5 columns.\n",
        "layer = tf.keras.layers.Dense(10, input_shape = (None, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gXop_Zb8tirH",
        "colab_type": "code",
        "outputId": "bb97fb90-72f9-461e-9b5e-7915dff19ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# To use a layer, simply call it.\n",
        "## Load a tensor of zeros with 10 rows and 5 columns\n",
        "layer(tf.zeros([10, 5]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=665, shape=(10, 10), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "f85BT5mOt_ON",
        "colab_type": "code",
        "outputId": "b1f775aa-6a59-4461-db39-41c1866659ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "# Layers have many useful methods. For example, you can inspect all variables\n",
        "# in a layer by calling layer.variables. In this case a fully-connected layer\n",
        "# will have variables for weights and biases.\n",
        "## Output the parameters of all the layers \n",
        "layer.variables"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
              " array([[-2.5663665e-01, -5.8177799e-01,  1.8449670e-01, -2.9094586e-01,\n",
              "         -4.1497099e-01, -5.5138874e-01, -1.1642277e-02,  4.5973164e-01,\n",
              "         -3.2897383e-01,  2.0703471e-01],\n",
              "        [-1.5895364e-01, -4.9259466e-01, -3.0101585e-01,  2.0438445e-01,\n",
              "          1.1554521e-01, -2.6928544e-01, -2.7084821e-01, -5.1827544e-01,\n",
              "          4.1160446e-01, -4.5114666e-01],\n",
              "        [ 4.7656757e-01, -5.6489599e-01, -5.2124447e-01,  2.2124779e-01,\n",
              "         -3.4935403e-01,  1.7513740e-01,  3.4350222e-01, -5.2504945e-01,\n",
              "          1.8486959e-01, -1.5126956e-01],\n",
              "        [-2.1642736e-01,  3.8950324e-02, -1.5366077e-04, -4.7530580e-01,\n",
              "          3.9836526e-02,  1.8192589e-02,  2.8634286e-01, -1.4674303e-01,\n",
              "          6.1877769e-01,  5.7627374e-01],\n",
              "        [ 8.0519915e-04,  3.6500633e-02, -3.7201205e-01,  1.7403287e-01,\n",
              "          6.8450272e-02,  2.1711373e-01,  5.8465141e-01, -5.1684564e-01,\n",
              "          5.9309536e-01, -1.8231902e-01]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "EX85klnnuW1u",
        "colab_type": "code",
        "outputId": "74ad4d41-fc93-4bb6-b869-9a142d752add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "## Show parameters of model broken down into kernel and bias parameters\n",
        "layer.kernel, layer.bias"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
              " array([[-2.5663665e-01, -5.8177799e-01,  1.8449670e-01, -2.9094586e-01,\n",
              "         -4.1497099e-01, -5.5138874e-01, -1.1642277e-02,  4.5973164e-01,\n",
              "         -3.2897383e-01,  2.0703471e-01],\n",
              "        [-1.5895364e-01, -4.9259466e-01, -3.0101585e-01,  2.0438445e-01,\n",
              "          1.1554521e-01, -2.6928544e-01, -2.7084821e-01, -5.1827544e-01,\n",
              "          4.1160446e-01, -4.5114666e-01],\n",
              "        [ 4.7656757e-01, -5.6489599e-01, -5.2124447e-01,  2.2124779e-01,\n",
              "         -3.4935403e-01,  1.7513740e-01,  3.4350222e-01, -5.2504945e-01,\n",
              "          1.8486959e-01, -1.5126956e-01],\n",
              "        [-2.1642736e-01,  3.8950324e-02, -1.5366077e-04, -4.7530580e-01,\n",
              "          3.9836526e-02,  1.8192589e-02,  2.8634286e-01, -1.4674303e-01,\n",
              "          6.1877769e-01,  5.7627374e-01],\n",
              "        [ 8.0519915e-04,  3.6500633e-02, -3.7201205e-01,  1.7403287e-01,\n",
              "          6.8450272e-02,  2.1711373e-01,  5.8465141e-01, -5.1684564e-01,\n",
              "          5.9309536e-01, -1.8231902e-01]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "oeEIEAEMwf68",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Implementing Custom Layers**"
      ]
    },
    {
      "metadata": {
        "id": "Y3GFk7tfwcjZ",
        "colab_type": "code",
        "outputId": "553ec3ab-7414-4448-dc04-4a3a40e78d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "## Create own layer by extending the current layer\n",
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "  ## Initialise new layer type by inheriting __init__ from original layer type \n",
        "  ## and then allowing specification of num_outputs\n",
        "  def __init__(self, num_outputs):\n",
        "    ## Inherit initiailisation from superclass\n",
        "    super(MyDenseLayer, self).__init__()\n",
        "    ## Make the number of inputs a class variable\n",
        "    self.num_outputs = num_outputs\n",
        "    \n",
        "  ## Do initialisation when knowing the shape of the input tensors\n",
        "  ## Build layer based on provided input shape and num_outputs\n",
        "  def build(self, input_shape):\n",
        "    self.kernel = self.add_variable(\"kernel\", \n",
        "                                    shape = [int(input_shape[-1]),\n",
        "                                             self.num_outputs])\n",
        "  \n",
        "  ## Perform the forward computation of the custom layer\n",
        "  def call(self, input):\n",
        "    ## Multiply the model kernel parameters by the inputs\n",
        "    return tf.matmul(input, self.kernel)\n",
        "  \n",
        "## Create a layer of 10 nodes (so 10 outputs) \n",
        "layer = MyDenseLayer(10)\n",
        "## Print the layer after loading into it a 10 row and 5 column zeros matrix\n",
        "print(layer(tf.zeros([10, 5])))\n",
        "## Print the parameters of the model\n",
        "print(layer.variables)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
            "[<tf.Variable 'my_dense_layer_4/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
            "array([[-0.40735114, -0.6300019 , -0.25971937,  0.2380225 , -0.01751357,\n",
            "        -0.60662204, -0.4422614 , -0.37311056, -0.22520524, -0.07270628],\n",
            "       [-0.16349313, -0.5921618 ,  0.48648435, -0.1005854 ,  0.1952287 ,\n",
            "         0.5262118 , -0.40402353,  0.50226647,  0.596348  ,  0.11827493],\n",
            "       [ 0.37935656, -0.22028893, -0.21772596, -0.55010206,  0.16215414,\n",
            "        -0.6152188 ,  0.1466257 , -0.06963807, -0.44268936,  0.11906266],\n",
            "       [-0.6288277 , -0.3336715 ,  0.5596054 , -0.5340312 , -0.03087139,\n",
            "         0.53430027, -0.30667317, -0.20834431, -0.48240858, -0.01448238],\n",
            "       [ 0.01142502, -0.4790832 ,  0.1971696 , -0.26971143,  0.22255033,\n",
            "        -0.12036264,  0.0079152 , -0.5504517 , -0.08742934,  0.5025802 ]],\n",
            "      dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q5zeh3zaRRJt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Models: Composing Layers**"
      ]
    },
    {
      "metadata": {
        "id": "gDvAwmsuxyho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "824288fd-4609-4cce-e100-8fccd301721c"
      },
      "cell_type": "code",
      "source": [
        "## Create a layer like thing by composing existing layers by inheriting from \n",
        "## keras model class \n",
        "class ResnetIdentityBlock(tf.keras.Model):\n",
        "  ## Initialise new class\n",
        "  def __init__(self, kernel_size, filters):\n",
        "    ## Inherit initialisation from keras model class\n",
        "    super(ResnetIdentityBlock, self).__init__(name='')\n",
        "    ## Unpack filters into three separate variables\n",
        "    ## Filters give dimensiality of the output space\n",
        "    filters1, filters2, filters3 = filters\n",
        "    \n",
        "    ## filter1 is the output from the convolution space\n",
        "    ## (1, 1) is the kernel size that specifies the height and width of the \n",
        "    ## 2d convolution window.\n",
        "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
        "    ## Normalizes the activation of the previous layer. This one applies a \n",
        "    ## transformation to the activations layer making the mean activation close \n",
        "    ## to 0 and standard deviation close to 1.\n",
        "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    ## Create a convolutional layer with an output of filter2 and taking in \n",
        "    ## kernel sizes of kernel_size. \n",
        "    ## Also applies padding, but not sure what 'same' means\n",
        "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding = 'same')\n",
        "    ## Normalises the activation of the previous layer. This one applies a \n",
        "    ## transformation to the activation layer making the mean activation close\n",
        "    ## to 0 and standard deviation close to 1.\n",
        "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    ## Create a convolutional layer with an output of filter 3and taking in a \n",
        "    ## kernel size of 1 row by 1 column\n",
        "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
        "    ## Normalises the activation of the previous layer. This one applies a \n",
        "    ## transformation to the activation layer making the mean activation close \n",
        "    ## to 0 and standard deviation close to 1\n",
        "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "  ## Does a forward pass of the model taking the input data through the \n",
        "  ## convolutional neural network\n",
        "  def call(self, input_tensor, training = False):\n",
        "    ## Run the custom convolutional conv2a specified in __init__ specified above\n",
        "    x = self.conv2a(input_tensor)\n",
        "    ## Run the above custom layer normalisation specified in __init__\n",
        "    x = self.bn2a(x, training = training)\n",
        "    ## Put the output from the activation layer through a non-linear relu \n",
        "    ## function\n",
        "    x = tf.nn.relu(x)\n",
        "    \n",
        "    ## Run the custom convolution function conv2b specified in __init__ above \n",
        "    x = self.conv2b(x)\n",
        "    ## Run the above custom normalisation specified in __init__\n",
        "    x = self.bn2b(x, training = training)\n",
        "    ## Put the output from the activation layer through a non-linear relu\n",
        "    ## function\n",
        "    x = tf.nn.relu(x)\n",
        "    \n",
        "    ## Run the custom concolution function conv2c specified in __init__ above\n",
        "    x = self.conv2c(x)\n",
        "    ## Run the above normalisation specified in the __init__ above\n",
        "    x = self.bn2c(x, training = training)\n",
        "    \n",
        "    ## Add the input tensor to the output (not sure why???) \n",
        "    x += input_tensor\n",
        "    ## Run the output a final time through a non-linear relu function\n",
        "    return tf.nn.relu(x)\n",
        "  \n",
        "## Create an instance of the ResnetIdnetityBlock class\n",
        "block = ResnetIdentityBlock(1, [1, 2, 3])\n",
        "## Run a tensor of zeros through the class instance\n",
        "print(block(tf.zeros([1, 2, 3, 3])))\n",
        "## Output the tensor being run through the model\n",
        "print([x.name for x in block.variables])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]\n",
            "   [0. 0. 0.]]]], shape=(1, 2, 3, 3), dtype=float32)\n",
            "['resnet_identity_block/conv2d/kernel:0', 'resnet_identity_block/conv2d/bias:0', 'resnet_identity_block/batch_normalization/gamma:0', 'resnet_identity_block/batch_normalization/beta:0', 'resnet_identity_block/conv2d_1/kernel:0', 'resnet_identity_block/conv2d_1/bias:0', 'resnet_identity_block/batch_normalization_1/gamma:0', 'resnet_identity_block/batch_normalization_1/beta:0', 'resnet_identity_block/conv2d_2/kernel:0', 'resnet_identity_block/conv2d_2/bias:0', 'resnet_identity_block/batch_normalization_2/gamma:0', 'resnet_identity_block/batch_normalization_2/beta:0', 'resnet_identity_block/batch_normalization/moving_mean:0', 'resnet_identity_block/batch_normalization/moving_variance:0', 'resnet_identity_block/batch_normalization_1/moving_mean:0', 'resnet_identity_block/batch_normalization_1/moving_variance:0', 'resnet_identity_block/batch_normalization_2/moving_mean:0', 'resnet_identity_block/batch_normalization_2/moving_variance:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R-KOU7UJUIE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c4088a0a-3ef5-4e95-e475-82a6f8699789"
      },
      "cell_type": "code",
      "source": [
        "## Create a more staright forward model by calling the layers one after another \n",
        "## to be run sequentially\n",
        "\n",
        "## The first layer is a convolutional layer with an output of one and blocks of\n",
        "## 1 row by 1 column\n",
        "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, [1, 1]),\n",
        "## Normalise the previous layer to mean of 0 and std of 1\n",
        "                             tf.keras.layers.BatchNormalization(),\n",
        "## Run a second convolutional layer with an output of 2 dimensions and blocks of\n",
        "## an input of 1 and padding.\n",
        "                             tf.keras.layers.Conv2D(2, 1,\n",
        "                                                   padding = 'same'),\n",
        "## Normalise the previous layer to a mean of 0 and std of 1\n",
        "                             tf.keras.layers.BatchNormalization(),\n",
        "## Run a third convolutional layer of with output of 3 dimensions and a input of\n",
        "## a 1 x 1 tensor\n",
        "                             tf.keras.layers.Conv2D(3, (1, 1)), \n",
        "## Normalise the activation layer so the mean is 0 and std is 1\n",
        "                             tf.keras.layers.BatchNormalization()])\n",
        "## Run the above model with a tensor of 0's as input\n",
        "my_seq(tf.zeros([1, 2, 3, 3]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=628, shape=(1, 2, 3, 3), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "Phsf6lNKVOQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}